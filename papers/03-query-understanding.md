# 查询理解

Query Understanding & Information Retrieval

---

## <a name="llm-cis"></a>Query Understanding in LLM-based Conversational Information Seeking

**⭐ 优先级: P0 | 相关性: ⭐⭐⭐⭐⭐**

### 基本信息
- **发表**: 2025-04-09
- **链接**: https://arxiv.org/abs/2504.06356

### 核心问题
在对话式信息检索（CIS）中，如何准确理解用户意图？

### 关键挑战

#### 1. 上下文依赖
- 用户查询通常是简短的、省略的
- 需要结合对话历史才能理解完整意图
- **示例**: "那个算法" → 需要回顾之前讨论过哪些算法

#### 2. 歧义消解
- 同一个词在不同上下文中有不同含义
- 需要动态推断用户的真实意图
- **示例**: "苹果" → 水果 or 公司？

#### 3. 意图演化
- 用户意图在对话过程中可能发生变化
- 需要追踪意图的演进路径
- **示例**: 从"了解概念"到"实现细节"

### 方法论

#### 传统方法的局限
- ❌ 关键词匹配：无法理解隐含意图
- ❌ 实体识别：无法处理指代消解
- ❌ 通用向量：无法理解个性化语境

#### 大模型时代的新方法
✅ **上下文感知**
- 将最近 N 轮对话作为上下文
- 理解指代关系（"它"、"那个"、"上次的"）

✅ **意图分解**
- 将复杂查询拆解为子意图
- 分别处理每个子查询

✅ **推理增强**
- 利用 LLM 的推理能力
- 推断隐含的意图和约束

### 对本项目的启发

✅ **Query Understanding 是第一层的核心**
- 不是简单的关键词提取，而是深度意图理解
- 需要结合对话历史和用户画像

✅ **实现路径**
```
User Query
    ↓
┌────────────────────┐
│ Query Understanding│
│ - 上下文注入       │
│ - 指代消解         │
│ - 意图分解         │
└────────────────────┘
    ↓
Structured Query
    ↓
Memory Retrieval
```

### 待探索问题
- 如何在千级记忆规模下高效实现 Query Understanding？
- 是否需要单独的 QU 模型，还是直接用 LLM？
- 如何平衡理解深度和响应速度？

---

## <a name="reasoning"></a>Reasoning-enhanced Query Understanding through Decomposition and Interpretation

**⭐ 优先级: P1 | 相关性: ⭐⭐⭐⭐**

### 基本信息
- **发表**: 2025-09-08
- **链接**: https://arxiv.org/abs/2509.06544

### 核心创新
通过**推理增强**来提升查询理解能力。

### 方法论

#### 查询分解（Decomposition）
将复杂查询拆解为多个子查询：
- **示例**: "之前我们讨论过的那个关于算法优化的问题"
  - 子查询 1: 什么时候讨论过？
  - 子查询 2: 关于什么算法？
  - 子查询 3: 优化的是什么指标？

#### 推理解释（Interpretation）
利用 LLM 推理能力推断隐含意图：
- **示例**: "类似的情况"
  - 推理: 用户想找语义相似 + 场景相似的记忆
  - 而非单纯的关键词匹配

### 实验结果
- 推理增强显著优于传统方法
- 在复杂查询场景下效果尤其明显

### 对本项目的启发
- ✅ Query Understanding 应该是一个**多步推理过程**
- ✅ 不要急于召回，先把查询"理解透"

---

## <a name="query-llm"></a>Query Understanding in the Age of Large Language Models

**⭐ 优先级: P1 | 相关性: ⭐⭐⭐⭐**

### 基本信息
- **发表**: 2023-06-28
- **链接**: https://arxiv.org/abs/2306.16004

### 核心观点
大模型时代的查询理解范式正在发生根本性变化。

### 传统范式 vs 大模型范式

| 维度 | 传统方法 | 大模型方法 |
|------|---------|-----------|
| **输入** | 关键词序列 | 自然语言 |
| **理解** | 分词 + 实体识别 | 深度语义理解 |
| **表示** | Bag of Words / TF-IDF | 上下文感知向量 |
| **能力** | 字面匹配 | 意图推理 |

### 大模型的优势
- ✅ 理解省略和指代
- ✅ 推断隐含意图
- ✅ 处理多义词和歧义
- ✅ 结合对话上下文

### 对本项目的启发
- 💡 应该充分利用 LLM 的理解能力
- 💡 不要退化到传统的关键词匹配

---

## <a name="graph-bert"></a>Graph Enhanced BERT for Query Understanding

**⭐ 优先级: P2 | 相关性: ⭐⭐⭐**

### 基本信息
- **发表**: SIGIR 2023
- **链接**: https://arxiv.org/abs/2204.06522

### 核心观点
利用图结构增强查询理解。

### 方法论
- 构建实体关系图
- 将图结构信息融入 BERT 编码
- 增强对实体和关系的理解

### 对本项目的启发
- 💡 可以考虑构建「记忆图谱」
- 💡 用图结构表示记忆之间的关联关系

### 适用场景
- 记忆规模较大（万级以上）
- 需要挖掘复杂的记忆关联

---

## 其他相关论文

### DeepRetrieval: Query Generation with Reinforcement Learning
- **链接**: https://www.researchgate.net/publication/389547553
- **主题**: 强化学习优化查询生成
- **相关性**: ⭐⭐ 适用于海量检索场景

### Query Understanding via Intent Description Generation
- **发表**: CIKM 2020
- **链接**: https://dl.acm.org/doi/10.1145/3340531.3411999
- **主题**: 通过生成意图描述来理解查询
- **相关性**: ⭐⭐⭐ 提供了另一种理解查询的视角

---

_最后更新: 2026-02-21_
