# Phase 1 具体实施方案

> 状态: 草案讨论中
> 创建: 2026-02-22
> 基于: SeCom (ICLR 2025) + Mem0 (arXiv 2504.19413) 论文研究成果

## 一、整体架构

```
┌──────────────────────────────────────────────────────────────────┐
│                        分身推荐系统 Phase 1                       │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────┐    ┌──────────────┐    ┌───────────┐    ┌───────┐ │
│  │ 对话入口  │───→│ 记忆写入管线  │    │ 记忆检索  │───→│ 排序  │ │
│  │(OpenClaw) │    │  (异步后台)   │    │ (四路召回) │    │ Top-K │ │
│  └──────────┘    └──────────────┘    └───────────┘    └───────┘ │
│        │               │                    │              │     │
│        │         ┌─────┴──────┐       ┌────┴─────┐        │     │
│        │         │ 主题分段    │       │ 时间路径  │        │     │
│        │         │ 去噪压缩    │       │ 标签路径  │        │     │
│        │         │ 事实提取    │       │ 文件路径  │        │     │
│        │         │ CRUD 更新   │       │ 文本搜索  │        │     │
│        │         └────────────┘       └──────────┘        │     │
│        │                                                   │     │
│        └──────────── 记忆存储层（Markdown 文件）─────────────┘     │
│          memory/daily/    memory/facts.md       memory/tags.json  │
└──────────────────────────────────────────────────────────────────┘
```

## 二、记忆存储结构

```
memory/
├── daily/                     # 日志层（原始对话记录）
│   ├── 2026-02-22.md
│   └── ...
├── segments/                  # 分段层（去噪后的主题段落）
│   ├── 2026-02-22-001.md      # segment: topic + facts + tags
│   ├── 2026-02-22-002.md
│   └── ...
├── facts.md                   # 事实层（Mem0 CRUD 自动维护的原子事实）
├── projects.md                # 项目追踪
│   注: insights.md 是用户手工维护的个人洞察笔记，不在本系统管理范围内
├── tags.json                  # 标签索引（倒排映射）
└── USER.md                    # 用户画像摘要（定期异步更新）
```

### 三层存储的设计理由

| 层级 | 内容 | 粒度 | 更新频率 | 论文依据 |
|------|------|------|---------|---------|
| **日志层** daily/ | 原始对话记录 | Session-level | 每次对话 | SeCom: 全量历史作为源数据保留 |
| **分段层** segments/ | 去噪后的主题段落 | Segment-level | 每次对话后异步 | SeCom: Segment-level 显著优于 Session-level |
| **事实层** facts.md | 系统自动维护的原子事实 | Fact-level | CRUD 动态维护 | Mem0: 1,764 tokens 达到全量 91.7% 效果 |

## 三、记忆写入管线（Write Pipeline）

每次对话结束后**异步执行**，不阻塞对话体验。

### Step 1: 主题分段

- **输入**: `daily/2026-02-22.md`（今日全部对话）
- **规则**: 时间间隔 > 30min OR 主题关键词变化 → 切分为新 Segment
- **输出**: `segments/2026-02-22-{N}.md`
- **模型**: 纯规则（Phase 1 不需要 ML 模型）

### Step 2: 去噪压缩

- **输入**: 每个 Segment 原文
- **方式**: TF-IDF 过滤低信息密度句（保留 Top 75%）
- **效果**: 去除寒暄、重复、口语填充
- **依据**: SeCom 验证去噪后召回率 87%→92%

### Step 3: 事实提取

- **输入**: 去噪后的 Segment
- **方式**: LLM 提取 salient facts（Mem0 Prompt 模板）
- **Prompt**: "从以下对话段落中提取关键事实。每条事实应是独立的、与用户相关的、未来可能有用的原子陈述。"
- **输出**: 候选事实列表 F = [f1, f2, ...]

### Step 4: CRUD 更新（Mem0 Algorithm 1）

对每条候选事实 f:

1. **语义匹配**: 在 facts.md 中找 top-5 最相似条目
   - Phase 1: 关键词重叠度 + LLM 判断
   - Phase 2: 换向量语义检索
2. **分类操作**: LLM 判断 f 与匹配项的关系
   - 无相似项 → **ADD**（新增到 facts.md）
   - 存在矛盾 → **DELETE** 旧条目 + **ADD** 新条目
   - 信息增强且更丰富 → **UPDATE**（替换旧条目）
   - 重复信息 → **NOOP**
3. **标签更新**: 从新增/更新的事实中提取关键词 → 更新 tags.json

### Step 5: 画像刷新（低频）

- **频率**: 每周一次 或手动触发
- **输入**: 最近 7 天的 facts.md 变更
- **方式**: LLM 总结用户兴趣/偏好/项目状态变化
- **输出**: 更新 USER.md 对应部分

## 四、记忆检索管线（Read Pipeline）

每次对话开始时**同步执行**，四路并行。

### 输入

用户消息 Q + USER.md 摘要

### 四路并行召回

| 路径 | 策略 | 数据源 | 候选数 |
|------|------|--------|-------|
| **时间路径** | 最近 3 天的所有 Segment，按时间倒序 | segments/ | ~10 条 |
| **标签路径** | 从 Q 提取关键词 → 查 tags.json 倒排索引 | tags.json → segments/ + facts.md | ~5 条 |
| **文件路径** | 优先检索 facts.md 高优先级事实 + projects.md 活跃项目 | facts.md, projects.md | ~3 条 |
| **文本搜索** | ripgrep 在 segments/ + facts.md 中全文匹配 | segments/, facts.md | ~5 条 |

### 轻量排序

```python
score = 标签匹配度 × 0.4
      + 时间衰减   × 0.3    # 半衰期 7 天
      + 文件优先级 × 0.3    # facts > segments > daily
```

- **约束**: Top-K（K=5~10），总 tokens < 1000
- **输出**: 拼接为 LLM 上下文（原文拼接，不做二次摘要）

## 五、数据格式设计

### 5.1 Segment 文件格式

```markdown
<!-- segments/2026-02-22-001.md -->
---
id: 2026-02-22-001
date: 2026-02-22
time_range: 09:15-09:42
topic: Mem0g 开源方案调研
tags: [Mem0, 图记忆, Neo4j, Kuzu]
fact_count: 3
---

Mem0g（Graph Memory）已完全开源，在 mem0ai/mem0 仓库中。
支持 4 种图数据库后端：Neo4j、Memgraph、Kuzu（嵌入式）、Neptune。
Kuzu 嵌入式方案零外部依赖，适合千级数据的原型验证。
```

### 5.2 facts.md 条目格式

```markdown
## 活跃事实

- [fact-050] **OpenClaw 记忆管理**: 已有 memory-manager skill，
  支持归档/检索/标签，但缺少 CRUD 更新和语义检索
  `tags: [OpenClaw, memory-manager]` `updated: 2026-02-22` `source: seg-2026-02-22-002`

- [fact-051] **Mem0g 技术选型**: 千级数据场景推荐 Kuzu 嵌入式，
  Phase 2 再考虑 Neo4j
  `tags: [Mem0, Kuzu, 技术选型]` `created: 2026-02-22` `source: seg-2026-02-22-001`

## 归档事实

（已完成/过时的事实，CRUD DELETE 后移入此区）
```

### 5.3 tags.json 倒排索引

```json
{
  "meta": {
    "last_updated": "2026-02-22T10:30:00",
    "total_tags": 42,
    "total_entries": 156
  },
  "index": {
    "SeCom": {
      "facts": ["fact-023", "fact-045"],
      "segments": ["2026-02-21-003", "2026-02-20-001"]
    },
    "推荐系统": {
      "facts": ["fact-001", "fact-012"],
      "segments": ["2026-02-22-001"]
    },
    "OpenClaw": {
      "facts": ["fact-050"],
      "segments": ["2026-02-22-002", "2026-02-21-005"]
    }
  }
}
```

## 六、与 OpenClaw 的集成点

| 集成点 | 触发方式 | 对应管线 |
|--------|---------|---------|
| **对话后记忆写入** | Heartbeat / 对话结束回调 | Write Pipeline 全流程 |
| **对话前记忆检索** | Agent 收到消息时自动触发 | Read Pipeline → 注入 System Prompt |
| **标签建议** | 写入时自动 + 手动 `/tag` 命令 | Step 4 标签更新 |
| **画像刷新** | Cron（每周日）或手动 `/refresh` | Step 5 |
| **记忆查询** | 手动 `/recall <query>` 命令 | Read Pipeline 单独执行 |

### 6.1 对话前记忆检索的实现机制（详细）

OpenClaw Agent 的每次会话启动流程定义在 `AGENTS.md` 中，当前已有 4 步固定流程：

```
Agent 收到用户消息
  ↓
Step 1: 读 SOUL.md（我是谁）
Step 2: 读 USER.md（用户是谁）
Step 3: 读 memory/YYYY-MM-DD.md（今天 + 昨天的日志）
Step 4: 读 MEMORY.md（长期记忆索引，仅主会话）
  ↓
开始回复用户
```

**改造方案**：在 Step 3 和 Step 4 之间插入一个 **Step 3.5: 记忆召回**，利用 `memory-manager` skill 的检索能力，基于用户消息执行四路召回。

#### 改造后的完整流程

```
Agent 收到用户消息 Q
  ↓
Step 1: 读 SOUL.md
Step 2: 读 USER.md → 提取用户画像摘要 S
Step 3: 读 memory/今天.md + 昨天.md → 近期上下文
  ↓
Step 3.5: 记忆召回（NEW）
  ├── 输入: Q + S
  ├── 执行: memory-manager skill 的 Read Pipeline
  │   ├── 路径1: 时间路径 → segments/ 最近 3 天
  │   ├── 路径2: 标签路径 → tags.json 倒排索引
  │   ├── 路径3: 文件路径 → facts.md + projects.md
  │   └── 路径4: 文本搜索 → ripgrep segments/ + facts.md
  ├── 排序: score = 标签×0.4 + 时间×0.3 + 文件优先级×0.3
  ├── 输出: Top-K 记忆片段（<1000 tokens）
  └── 注入: 作为 System Prompt 的 [相关记忆] 部分
  ↓
Step 4: 读 MEMORY.md（长期记忆索引，仅主会话）
  ↓
组装完整上下文 → 回复用户
```

#### 具体实现方式：修改 SKILL.md

在 `memory-manager` 的 SKILL.md 中新增一个 **Pattern D: 自动召回**：

```markdown
### Pattern D: 自动召回（对话前触发）

每次收到用户消息时，在回复前自动执行：

1. 从用户消息 Q 中提取关键词（不需要 LLM，规则提取即可）
2. 运行 scripts/recall_memory.py --query "Q的关键词"
   - 时间路径: 列出 segments/ 最近 3 天文件
   - 标签路径: 在 tags.json 中匹配关键词
   - 文件路径: 读取 facts.md 中匹配的条目
   - 文本搜索: ripgrep 在 segments/ + facts.md 中搜索
3. 对候选结果加权排序，取 Top-5（<1000 tokens）
4. 将结果注入 System Prompt：

   [相关记忆]
   - {memory_1}
   - {memory_2}
   ...

5. 如果四路召回均无结果 → 跳过，不注入任何记忆
```

#### 触发控制：避免每条消息都召回

并非所有消息都需要召回（如 "好的" "谢谢" 等简短回复）。通过以下规则过滤：

| 条件 | 是否触发召回 | 理由 |
|------|------------|------|
| 用户消息 < 5 字 | ❌ 跳过 | 太短，无法提取有效关键词 |
| 用户消息是纯确认词（好/嗯/ok） | ❌ 跳过 | 无需召回上下文 |
| 对话中已召回过且话题未切换 | ❌ 跳过 | 避免重复检索相同内容 |
| 用户消息包含问句或新话题关键词 | ✅ 触发 | 新话题需要新的记忆上下文 |
| 用户消息 > 20 字且含实体/项目名 | ✅ 触发 | 可能涉及具体项目/决策 |

#### 与现有 MEMORY.md 召回映射表的关系

当前 `MEMORY.md` 已有一个手工的"记忆召回快速映射表"：

```
| 用户问         | 优先读取                    |
| "分身项目"     | facts.md (#AI/分身)         |
| "上次/继续讨论" | 最近 3 天日志（倒序）         |
```

Phase 1 的四路召回**替代**这个手工映射表，将其自动化：

| 现有手工映射 | Phase 1 自动化替代 |
|------------|-------------------|
| 按关键词手工匹配文件 | 标签路径自动匹配 tags.json |
| "最近 3 天日志倒序" | 时间路径自动读取 segments/ |
| "facts.md 标签筛选" | 文件路径 + 标签路径联合检索 |
| 按优先级顺序尝试 | 四路并行 + 加权排序，一次完成 |

#### 上下文注入格式

召回结果注入到 Agent 的 System Prompt 中，格式如下：

```
[系统] 你是林风过竹，用户的分身。

[用户画像]
{USER.md 摘要}

[相关记忆] （由记忆检索系统自动召回，共 {N} 条，{T} tokens）
1. [2026-02-22] Mem0g 已开源，支持 Neo4j/Memgraph/Kuzu/Neptune
   来源: seg-2026-02-22-001 | 标签: Mem0, 图记忆
2. [2026-02-21] 分身推荐系统采用两层检索架构，第一层四路规则召回
   来源: fact-042 | 标签: 推荐系统, 架构
3. ...

[近期上下文]
{今天 + 昨天的日志摘要}

[用户消息]
{Q}
```

#### 延迟预算分配

总预算 < 2s，各环节分配：

| 环节 | 预算 | 说明 |
|------|------|------|
| 关键词提取 | < 50ms | 纯规则，正则 + 停用词过滤 |
| 时间路径 | < 100ms | 文件系统 ls + 读取 |
| 标签路径 | < 50ms | JSON 查表 |
| 文件路径 | < 100ms | 读取 facts.md 匹配段落 |
| 文本搜索 | < 200ms | ripgrep 全文检索 |
| 排序 + 截断 | < 50ms | 内存计算 |
| **总计** | **< 550ms** | 远低于 2s 预算 |

> 注：以上均为本地文件操作，不涉及 LLM 调用。LLM 仅在 Write Pipeline 中使用（事实提取 + CRUD 分类），Read Pipeline 全程无 LLM 依赖，这是延迟极低的关键。

## 七、关键指标与验证方法

| 指标 | 目标 | 验证方式 |
|------|------|---------|
| **检索延迟** | < 2s | 计时：四路并行 + 排序总耗时 |
| **Token 效率** | < 1000 tokens | 统计 Top-K 拼接后的 token 数 |
| **召回相关性** | > 80% | 人工评估：10 次对话中 Top-5 结果是否相关 |
| **CRUD 准确率** | > 90% | 人工审核：每周检查 facts.md 的自动变更是否合理 |
| **去噪压缩率** | 50%-75% | Segment 原文 vs 去噪后的 token 比 |

## 八、闭环验证环境

### 8.1 核心原则

**不搭建独立测试环境，直接在 OpenClaw 真实对话中验证。** 每一小步开发完成后，立即部署到林风过竹的真实工作流中，通过飞书对话感知效果变化。

```
每一小步的闭环：
  开发脚本/规则 → 部署到 OpenClaw workspace → 飞书对话验证 → 观察效果 → 调优
```

### 8.2 验证基准：10 个标准问题

每完成一步，用以下问题在飞书和林风过竹对话，观察回复质量变化：

| ID | Query | 预期能力 | 当前效果（基线） |
|----|-------|---------|----------------|
| Q01 | "分身项目的进展" | 召回相关记忆 | ❓ 待记录 |
| Q02 | "上次讨论了什么" | 命中最近日志 | ❓ 待记录 |
| Q03 | "大疆运动相机选哪个" | 召回购物决策 | ❓ 待记录 |
| Q04 | "OpenClaw Skill 有什么问题" | 召回反思结论 | ❓ 待记录 |
| Q05 | "双塔架构怎么设计的" | 召回架构讨论 | ❓ 待记录 |
| Q06 | "团队有多少人" | 召回组织信息 | ❓ 待记录 |
| Q07 | "公众号有多少粉丝" | 召回公众号数据 | ❓ 待记录 |
| Q08 | "贴图号灰度情况" | 召回项目状态 | ❓ 待记录 |
| Q09 | "组织扁平化的思考" | 召回讨论洞察 | ❓ 待记录 |
| Q10 | "好的" | 不触发召回 | ❓ 待记录 |

> **第一步（Step 0）就是先记录基线**：在任何改造之前，用这 10 个问题问一遍林风过竹，记录当前回复质量作为对照。

## 九、实施计划（10 步渐进式）

每一步都是：**开发 → 部署到 OpenClaw → 飞书对话验证 → 记录效果变化**。

### Step 0: 记录基线（0.5h）

- **动作**：用 10 个标准问题问林风过竹，记录当前回复
- **部署**：无
- **验证**：记录每个问题的回复质量（0-5 分），作为后续对比的基线
- **产出**：`docs/06-verify-baseline.md`

---

### Step 1: 对历史日志跑主题分段（2h）

- **开发**：`scripts/segment.py` — 纯规则分段（时间间隔 + 主题变化）
- **输入**：`memory/` 下现有的 7 个日志文件
- **输出**：`memory/segments/` 目录，生成 ~15-20 个 segment 文件
- **部署**：脚本跑一次，segments 直接写入 OpenClaw workspace
- **验证**：
  - 自动：检查 segment 文件数量、格式、frontmatter 完整性
  - 人工：抽查 3 个 segment，确认边界合理
- **飞书可观察变化**：暂无（segments 还没接入检索）

### Step 2: 接入文本搜索路径（1h）

- **开发**：修改 `AGENTS.md`，在 Step 3 后增加一条规则：
  > "回复前，先用 ripgrep 在 `memory/segments/` 中搜索用户消息的关键词，将匹配结果作为参考"
- **部署**：直接修改 `AGENTS.md`（一行规则即可）
- **验证**：飞书问 Q05"双塔架构怎么设计的" → 林风过竹应能从 segments 中找到 02-20-evening 的分段内容
- **飞书可观察变化**：**对具体关键词的问题，回复质量应明显提升**
- **对比基线**：重新问 Q05/Q06/Q07，对比 Step 0 的回复

### Step 3: 去噪压缩 segments（1.5h）

- **开发**：`scripts/denoise.py` — 对 segments 做去噪（去寒暄/重复）
- **输入**：`memory/segments/` 中的文件
- **输出**：覆盖写入 segments（或写入 segments 的正文部分）
- **部署**：脚本跑一次，覆盖更新 segments
- **验证**：
  - 自动：检查压缩率 50%-75%
  - 人工：抽查 3 个 segment，确认关键信息未丢失
- **飞书可观察变化**：ripgrep 搜索结果更精准（噪声减少）
- **对比 Step 2**：重新问 Q05/Q06，对比回复是否更聚焦

### Step 4: 建 tags.json 倒排索引（1.5h）

- **开发**：`scripts/build_tags.py` — 从 segments 的 frontmatter 提取标签，生成 tags.json
- **输出**：`memory/tags.json`
- **部署**：脚本跑一次，tags.json 写入 workspace
- **验证**：
  - 自动：检查 tags.json 格式、标签数量、条目映射
  - 人工：抽查 5 个标签，确认映射正确
- **飞书可观察变化**：暂无（标签路径还没接入）

### Step 5: 接入标签路径检索（1h）

- **开发**：修改 `AGENTS.md`，增加标签检索规则：
  > "回复前，从用户消息提取关键词，查 `memory/tags.json` 找到相关 segments，优先参考"
- **部署**：修改 `AGENTS.md`
- **验证**：飞书问 Q01"分身项目的进展" → 应通过"分身""项目"标签命中相关 segments
- **飞书可观察变化**：**对标签匹配的问题，召回精度提升**
- **对比 Step 2**：重新问 Q01/Q03/Q04/Q08/Q09，对比效果

### Step 6: 事实提取 → 生成 facts.md（2h）

- **开发**：`scripts/extract_facts.py` — LLM 从 segments 提取原子事实
- **输入**：去噪后的 segments
- **输出**：`memory/facts.md`
- **部署**：脚本跑一次，facts.md 写入 workspace
- **验证**：
  - 人工：逐条审核 facts.md，确认事实准确、无幻觉
  - 检查：事实条目数、标签覆盖度
- **飞书可观察变化**：暂无（facts.md 还没接入检索）

### Step 7: 接入文件路径检索（0.5h）

- **开发**：修改 `AGENTS.md`，增加 facts.md 检索规则：
  > "回复前，检索 `memory/facts.md` 中与用户问题相关的事实条目"
- **部署**：修改 `AGENTS.md`
- **验证**：飞书问 Q06"团队有多少人" → 应直接从 facts.md 找到精确答案
- **飞书可观察变化**：**对事实性问题，回复准确度大幅提升**
- **对比 Step 5**：重新问 Q06/Q07/Q08，对比效果

### Step 8: 轻量排序 + Token 控制（1.5h）

- **开发**：`scripts/recall_memory.py` — 四路合并、加权排序、Top-K 截断
- **部署**：修改 `AGENTS.md`，将 Step 2/5/7 的分散规则合并为调用 `recall_memory.py`
- **验证**：
  - 自动：检查输出 token 数 < 1000，Top-K 数量合理
  - 飞书：10 个标准问题全部重新测试
- **飞书可观察变化**：**回复质量稳定，不再因召回过多导致上下文混乱**
- **对比 Step 7**：全量 10 个问题对比

### Step 9: CRUD 增量更新（2h）

- **开发**：`scripts/update_facts.py` — 新对话后的增量事实更新（Mem0 CRUD）
- **触发**：手动或 Heartbeat 调用
- **部署**：今天和林风过竹聊几个新话题，然后跑增量更新
- **验证**：
  - 人工：检查 facts.md 的变更是否合理（新增/更新/无操作）
  - 飞书：问刚才聊过的新话题，看能否正确召回
- **飞书可观察变化**：**新聊的内容也能被记住并召回**

### Step 10: 触发控制 + 画像刷新（1h）

- **开发**：在 `recall_memory.py` 中增加触发判断逻辑；`scripts/refresh_profile.py` 更新 USER.md
- **部署**：更新脚本 + AGENTS.md
- **验证**：
  - 飞书问 Q10"好的" → 确认不触发召回
  - 飞书问 Q01-Q09 → 确认正常召回
  - 检查 USER.md 画像更新是否合理
- **飞书可观察变化**：短消息不再有不相关的记忆注入

---

### 效果可见性总览

| Step | 完成后飞书可观察到的变化 | 累计耗时 |
|------|------------------------|---------|
| 0 | 基线记录 | 0.5h |
| 1 | （内部准备） | 2.5h |
| **2** | **关键词搜索首次生效：问具体话题能召回历史** | 3.5h |
| 3 | 搜索结果更精准 | 5h |
| 4 | （内部准备） | 6.5h |
| **5** | **标签匹配生效：问抽象话题也能召回** | 7.5h |
| 6 | （内部准备） | 9.5h |
| **7** | **事实库生效：问事实性问题直接给精确答案** | 10h |
| **8** | **四路合并：回复质量全面稳定** | 11.5h |
| **9** | **增量更新：新对话也能被记住** | 13.5h |
| 10 | 触发控制完善，无噪声 | 14.5h |

> 关键里程碑在 Step 2/5/7/8/9，每个都能在飞书对话中直接感知到效果跳变。

## 十、待讨论问题

1. **Segment 分段规则的阈值**：30min 时间间隔是否合理？是否需要更细粒度？
2. **事实提取的 LLM 选择**：用 OpenClaw 内置 LLM（kimi-k2.5）还是外部 API？
3. **CRUD 的 Phase 1 语义匹配**：关键词重叠度足够吗？还是一开始就需要 embedding？
4. **排序权重**：0.4/0.3/0.3 的初始分配是否合理？
5. **图检索（Mem0g）何时引入**：Phase 1 末尾还是 Phase 2？
6. **facts.md 的容量上限**：事实条目增长到多少时需要考虑分文件？
7. **空召回处理**：四路都没有结果时，回退到最近记忆？还是返回空？

---

_创建: 2026-02-22_
_状态: 草案，待讨论确认后进入实现_
