# Phase 1 具体实施方案

> 状态: 草案讨论中
> 创建: 2026-02-22
> 基于: SeCom (ICLR 2025) + Mem0 (arXiv 2504.19413) 论文研究成果

## 一、整体架构

```
┌──────────────────────────────────────────────────────────────────┐
│                        分身推荐系统 Phase 1                       │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────┐    ┌──────────────┐    ┌───────────┐    ┌───────┐ │
│  │ 对话入口  │───→│ 记忆写入管线  │    │ 记忆检索  │───→│ 排序  │ │
│  │(OpenClaw) │    │  (异步后台)   │    │ (四路召回) │    │ Top-K │ │
│  └──────────┘    └──────────────┘    └───────────┘    └───────┘ │
│        │               │                    │              │     │
│        │         ┌─────┴──────┐       ┌────┴─────┐        │     │
│        │         │ 主题分段    │       │ 时间路径  │        │     │
│        │         │ 去噪压缩    │       │ 标签路径  │        │     │
│        │         │ 事实提取    │       │ 文件路径  │        │     │
│        │         │ CRUD 更新   │       │ 文本搜索  │        │     │
│        │         └────────────┘       └──────────┘        │     │
│        │                                                   │     │
│        └──────────── 记忆存储层（Markdown 文件）─────────────┘     │
│          memory/daily/    memory/insights.md    memory/tags.json  │
└──────────────────────────────────────────────────────────────────┘
```

## 二、记忆存储结构

```
memory/
├── daily/                     # 日志层（原始对话记录）
│   ├── 2026-02-22.md
│   └── ...
├── segments/                  # 分段层（去噪后的主题段落）
│   ├── 2026-02-22-001.md      # segment: topic + facts + tags
│   ├── 2026-02-22-002.md
│   └── ...
├── insights.md                # 事实层（Mem0 CRUD 自动维护）
├── projects.md                # 项目追踪
├── tags.json                  # 标签索引（倒排映射）
└── USER.md                    # 用户画像摘要（定期异步更新）
```

### 三层存储的设计理由

| 层级 | 内容 | 粒度 | 更新频率 | 论文依据 |
|------|------|------|---------|---------|
| **日志层** daily/ | 原始对话记录 | Session-level | 每次对话 | SeCom: 全量历史作为源数据保留 |
| **分段层** segments/ | 去噪后的主题段落 | Segment-level | 每次对话后异步 | SeCom: Segment-level 显著优于 Session-level |
| **事实层** insights.md | 原子事实集合 | Fact-level | CRUD 动态维护 | Mem0: 1,764 tokens 达到全量 91.7% 效果 |

## 三、记忆写入管线（Write Pipeline）

每次对话结束后**异步执行**，不阻塞对话体验。

### Step 1: 主题分段

- **输入**: `daily/2026-02-22.md`（今日全部对话）
- **规则**: 时间间隔 > 30min OR 主题关键词变化 → 切分为新 Segment
- **输出**: `segments/2026-02-22-{N}.md`
- **模型**: 纯规则（Phase 1 不需要 ML 模型）

### Step 2: 去噪压缩

- **输入**: 每个 Segment 原文
- **方式**: TF-IDF 过滤低信息密度句（保留 Top 75%）
- **效果**: 去除寒暄、重复、口语填充
- **依据**: SeCom 验证去噪后召回率 87%→92%

### Step 3: 事实提取

- **输入**: 去噪后的 Segment
- **方式**: LLM 提取 salient facts（Mem0 Prompt 模板）
- **Prompt**: "从以下对话段落中提取关键事实。每条事实应是独立的、与用户相关的、未来可能有用的原子陈述。"
- **输出**: 候选事实列表 F = [f1, f2, ...]

### Step 4: CRUD 更新（Mem0 Algorithm 1）

对每条候选事实 f:

1. **语义匹配**: 在 insights.md 中找 top-5 最相似条目
   - Phase 1: 关键词重叠度 + LLM 判断
   - Phase 2: 换向量语义检索
2. **分类操作**: LLM 判断 f 与匹配项的关系
   - 无相似项 → **ADD**（新增到 insights.md）
   - 存在矛盾 → **DELETE** 旧条目 + **ADD** 新条目
   - 信息增强且更丰富 → **UPDATE**（替换旧条目）
   - 重复信息 → **NOOP**
3. **标签更新**: 从新增/更新的事实中提取关键词 → 更新 tags.json

### Step 5: 画像刷新（低频）

- **频率**: 每周一次 或手动触发
- **输入**: 最近 7 天的 insights.md 变更
- **方式**: LLM 总结用户兴趣/偏好/项目状态变化
- **输出**: 更新 USER.md 对应部分

## 四、记忆检索管线（Read Pipeline）

每次对话开始时**同步执行**，四路并行。

### 输入

用户消息 Q + USER.md 摘要

### 四路并行召回

| 路径 | 策略 | 数据源 | 候选数 |
|------|------|--------|-------|
| **时间路径** | 最近 3 天的所有 Segment，按时间倒序 | segments/ | ~10 条 |
| **标签路径** | 从 Q 提取关键词 → 查 tags.json 倒排索引 | tags.json → segments/ + insights.md | ~5 条 |
| **文件路径** | 优先检索 insights.md 高优先级事实 + projects.md 活跃项目 | insights.md, projects.md | ~3 条 |
| **文本搜索** | ripgrep 在 segments/ + insights.md 中全文匹配 | segments/, insights.md | ~5 条 |

### 轻量排序

```python
score = 标签匹配度 × 0.4
      + 时间衰减   × 0.3    # 半衰期 7 天
      + 文件优先级 × 0.3    # insights > segments > daily
```

- **约束**: Top-K（K=5~10），总 tokens < 1000
- **输出**: 拼接为 LLM 上下文（原文拼接，不做二次摘要）

## 五、数据格式设计

### 5.1 Segment 文件格式

```markdown
<!-- segments/2026-02-22-001.md -->
---
id: 2026-02-22-001
date: 2026-02-22
time_range: 09:15-09:42
topic: Mem0g 开源方案调研
tags: [Mem0, 图记忆, Neo4j, Kuzu]
fact_count: 3
---

Mem0g（Graph Memory）已完全开源，在 mem0ai/mem0 仓库中。
支持 4 种图数据库后端：Neo4j、Memgraph、Kuzu（嵌入式）、Neptune。
Kuzu 嵌入式方案零外部依赖，适合千级数据的原型验证。
```

### 5.2 insights.md 条目格式

```markdown
## 活跃事实

- [insight-050] **OpenClaw 记忆管理**: 已有 memory-manager skill，
  支持归档/检索/标签，但缺少 CRUD 更新和语义检索
  `tags: [OpenClaw, memory-manager]` `updated: 2026-02-22` `source: seg-2026-02-22-002`

- [insight-051] **Mem0g 技术选型**: 千级数据场景推荐 Kuzu 嵌入式，
  Phase 2 再考虑 Neo4j
  `tags: [Mem0, Kuzu, 技术选型]` `created: 2026-02-22` `source: seg-2026-02-22-001`

## 归档事实

（已完成/过时的事实，CRUD DELETE 后移入此区）
```

### 5.3 tags.json 倒排索引

```json
{
  "meta": {
    "last_updated": "2026-02-22T10:30:00",
    "total_tags": 42,
    "total_entries": 156
  },
  "index": {
    "SeCom": {
      "insights": ["insight-023", "insight-045"],
      "segments": ["2026-02-21-003", "2026-02-20-001"]
    },
    "推荐系统": {
      "insights": ["insight-001", "insight-012"],
      "segments": ["2026-02-22-001"]
    },
    "OpenClaw": {
      "insights": ["insight-050"],
      "segments": ["2026-02-22-002", "2026-02-21-005"]
    }
  }
}
```

## 六、与 OpenClaw 的集成点

| 集成点 | 触发方式 | 对应管线 |
|--------|---------|---------|
| **对话后记忆写入** | Heartbeat / 对话结束回调 | Write Pipeline 全流程 |
| **对话前记忆检索** | Agent 收到消息时自动触发 | Read Pipeline → 注入 System Prompt |
| **标签建议** | 写入时自动 + 手动 `/tag` 命令 | Step 4 标签更新 |
| **画像刷新** | Cron（每周日）或手动 `/refresh` | Step 5 |
| **记忆查询** | 手动 `/recall <query>` 命令 | Read Pipeline 单独执行 |

### 6.1 对话前记忆检索的实现机制（详细）

OpenClaw Agent 的每次会话启动流程定义在 `AGENTS.md` 中，当前已有 4 步固定流程：

```
Agent 收到用户消息
  ↓
Step 1: 读 SOUL.md（我是谁）
Step 2: 读 USER.md（用户是谁）
Step 3: 读 memory/YYYY-MM-DD.md（今天 + 昨天的日志）
Step 4: 读 MEMORY.md（长期记忆索引，仅主会话）
  ↓
开始回复用户
```

**改造方案**：在 Step 3 和 Step 4 之间插入一个 **Step 3.5: 记忆召回**，利用 `memory-manager` skill 的检索能力，基于用户消息执行四路召回。

#### 改造后的完整流程

```
Agent 收到用户消息 Q
  ↓
Step 1: 读 SOUL.md
Step 2: 读 USER.md → 提取用户画像摘要 S
Step 3: 读 memory/今天.md + 昨天.md → 近期上下文
  ↓
Step 3.5: 记忆召回（NEW）
  ├── 输入: Q + S
  ├── 执行: memory-manager skill 的 Read Pipeline
  │   ├── 路径1: 时间路径 → segments/ 最近 3 天
  │   ├── 路径2: 标签路径 → tags.json 倒排索引
  │   ├── 路径3: 文件路径 → insights.md + projects.md
  │   └── 路径4: 文本搜索 → ripgrep segments/ + insights.md
  ├── 排序: score = 标签×0.4 + 时间×0.3 + 文件优先级×0.3
  ├── 输出: Top-K 记忆片段（<1000 tokens）
  └── 注入: 作为 System Prompt 的 [相关记忆] 部分
  ↓
Step 4: 读 MEMORY.md（长期记忆索引，仅主会话）
  ↓
组装完整上下文 → 回复用户
```

#### 具体实现方式：修改 SKILL.md

在 `memory-manager` 的 SKILL.md 中新增一个 **Pattern D: 自动召回**：

```markdown
### Pattern D: 自动召回（对话前触发）

每次收到用户消息时，在回复前自动执行：

1. 从用户消息 Q 中提取关键词（不需要 LLM，规则提取即可）
2. 运行 scripts/recall_memory.py --query "Q的关键词"
   - 时间路径: 列出 segments/ 最近 3 天文件
   - 标签路径: 在 tags.json 中匹配关键词
   - 文件路径: 读取 insights.md 中匹配的条目
   - 文本搜索: ripgrep 在 segments/ + insights.md 中搜索
3. 对候选结果加权排序，取 Top-5（<1000 tokens）
4. 将结果注入 System Prompt：

   [相关记忆]
   - {memory_1}
   - {memory_2}
   ...

5. 如果四路召回均无结果 → 跳过，不注入任何记忆
```

#### 触发控制：避免每条消息都召回

并非所有消息都需要召回（如 "好的" "谢谢" 等简短回复）。通过以下规则过滤：

| 条件 | 是否触发召回 | 理由 |
|------|------------|------|
| 用户消息 < 5 字 | ❌ 跳过 | 太短，无法提取有效关键词 |
| 用户消息是纯确认词（好/嗯/ok） | ❌ 跳过 | 无需召回上下文 |
| 对话中已召回过且话题未切换 | ❌ 跳过 | 避免重复检索相同内容 |
| 用户消息包含问句或新话题关键词 | ✅ 触发 | 新话题需要新的记忆上下文 |
| 用户消息 > 20 字且含实体/项目名 | ✅ 触发 | 可能涉及具体项目/决策 |

#### 与现有 MEMORY.md 召回映射表的关系

当前 `MEMORY.md` 已有一个手工的"记忆召回快速映射表"：

```
| 用户问         | 优先读取                    |
| "分身项目"     | insights.md (#AI/分身)      |
| "上次/继续讨论" | 最近 3 天日志（倒序）         |
```

Phase 1 的四路召回**替代**这个手工映射表，将其自动化：

| 现有手工映射 | Phase 1 自动化替代 |
|------------|-------------------|
| 按关键词手工匹配文件 | 标签路径自动匹配 tags.json |
| "最近 3 天日志倒序" | 时间路径自动读取 segments/ |
| "insights.md 标签筛选" | 文件路径 + 标签路径联合检索 |
| 按优先级顺序尝试 | 四路并行 + 加权排序，一次完成 |

#### 上下文注入格式

召回结果注入到 Agent 的 System Prompt 中，格式如下：

```
[系统] 你是林风过竹，用户的分身。

[用户画像]
{USER.md 摘要}

[相关记忆] （由记忆检索系统自动召回，共 {N} 条，{T} tokens）
1. [2026-02-22] Mem0g 已开源，支持 Neo4j/Memgraph/Kuzu/Neptune
   来源: seg-2026-02-22-001 | 标签: Mem0, 图记忆
2. [2026-02-21] 分身推荐系统采用两层检索架构，第一层四路规则召回
   来源: insight-042 | 标签: 推荐系统, 架构
3. ...

[近期上下文]
{今天 + 昨天的日志摘要}

[用户消息]
{Q}
```

#### 延迟预算分配

总预算 < 2s，各环节分配：

| 环节 | 预算 | 说明 |
|------|------|------|
| 关键词提取 | < 50ms | 纯规则，正则 + 停用词过滤 |
| 时间路径 | < 100ms | 文件系统 ls + 读取 |
| 标签路径 | < 50ms | JSON 查表 |
| 文件路径 | < 100ms | 读取 insights.md 匹配段落 |
| 文本搜索 | < 200ms | ripgrep 全文检索 |
| 排序 + 截断 | < 50ms | 内存计算 |
| **总计** | **< 550ms** | 远低于 2s 预算 |

> 注：以上均为本地文件操作，不涉及 LLM 调用。LLM 仅在 Write Pipeline 中使用（事实提取 + CRUD 分类），Read Pipeline 全程无 LLM 依赖，这是延迟极低的关键。

## 七、关键指标与验证方法

| 指标 | 目标 | 验证方式 |
|------|------|---------|
| **检索延迟** | < 2s | 计时：四路并行 + 排序总耗时 |
| **Token 效率** | < 1000 tokens | 统计 Top-K 拼接后的 token 数 |
| **召回相关性** | > 80% | 人工评估：10 次对话中 Top-5 结果是否相关 |
| **CRUD 准确率** | > 90% | 人工审核：每周检查 insights.md 的自动变更是否合理 |
| **去噪压缩率** | 50%-75% | Segment 原文 vs 去噪后的 token 比 |

## 八、实施节奏（3 周）

| 周次 | 目标 | 交付物 |
|------|------|--------|
| **Week 1** | 存储结构 + Write Pipeline 前半 | `memory/` 目录结构、主题分段规则、去噪脚本、Segment 文件生成 |
| **Week 2** | Write Pipeline 后半 + 标签索引 | insights.md 自动维护、tags.json 倒排索引、CRUD 分类 Prompt |
| **Week 3** | Read Pipeline + 排序 + 集成 | 四路召回实现、加权排序、OpenClaw Agent 集成、端到端测试 |

## 九、待讨论问题

1. **Segment 分段规则的阈值**：30min 时间间隔是否合理？是否需要更细粒度？
2. **事实提取的 LLM 选择**：用 OpenClaw 内置 LLM 还是外部 API？
3. **CRUD 的 Phase 1 语义匹配**：关键词重叠度足够吗？还是一开始就需要 embedding？
4. **排序权重**：0.4/0.3/0.3 的初始分配是否合理？文本搜索路径权重如何处理？
5. **图检索（Mem0g）何时引入**：Phase 1 末尾还是 Phase 2？千级数据是否值得？
6. **insights.md 的容量上限**：事实条目增长到多少时需要考虑分文件或归档？
7. **空召回处理**：四路都没有结果时，回退到最近记忆？还是返回空？

---

_创建: 2026-02-22_
_状态: 草案，待讨论确认后进入实现_
