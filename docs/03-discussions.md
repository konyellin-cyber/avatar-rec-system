# 架构演进记录

本文档记录分身推荐系统架构的演进过程和关键设计决策。

---

## 阶段 1: 识别核心需求

### 两个核心方向

**方向 1: 记忆的自动化规划与处理**
- **现状**: 手动分类、定期整理，依赖用户主动管理
- **目标**: 自动识别重要性、自动归档、智能提取待办
- **转变**: 从「人驱动」转向「Agent 主动管理」

**方向 2: 主动发起对话，深化理解**
- **现状**: 被动响应，等待用户提问
- **目标**: 基于记忆推断用户可能关心的议题，主动抛出讨论
- **转变**: 从「问答工具」转向「主动参与的思考伙伴」

### 延伸思考

这两个方向本质上是同一回事：**记忆的价值在于被使用**。

- 不是为了存而存，是为了在合适的时机被唤醒、被关联、被讨论
- 分身不是「更好的搜索引擎」，而是「一直在场、主动思考的另一个你」

### 飞轮循环

记忆系统应该形成**正向飞轮**:

```
更多数据输入（主动对话）
    ↓
更精准的用户画像
    ↓
更好的记忆整理（自动化）
    ↓
在正确时机调用正确信息
    ↓
主动对话质量提升
    ↓
用户更愿意分享
    ↓
回到起点
```

---

## 阶段 2: 双塔召回架构设计

### 问题定义

**典型场景**: 用户说"之前我们聊到过xxx"时，如何智能找到相关记忆？

**传统方案的不足**:
- **关键词匹配**: 无法理解隐含意图
- **实体索引**: 无法处理指代消解
- **向量检索**: 通用向量模型无法理解个性化语境

### 核心洞察

传统方案都只做**字面匹配**，而没有真正**理解用户意图**。现代 LLM 的能力完全可以用来做深度理解。

**推荐系统类比**:
跨会话记忆召回本质上是一个**双塔召回问题**——从候选记忆中找到与当前 Query 最相关的。

### 架构设计（三阶段）

#### Stage 1: Query Understanding (User Tower)

```
LLM Query Rewrite:
- 指代消解: "那个东西" → "大疆相机"
- 意图推断: "决定了" → 需要调用对比记录
- 实体提取: ["大疆相机", "Action 5 Pro", "Nano"]
```

#### Stage 2: Memory Retrieval (Dual Tower Recall)

```
多路召回:
├─ 实体路径: 根据实体查找
├─ 标签路径: 根据主题标签
├─ 向量路径: 语义相似度
├─ 时间路径: 最近讨论
└─ 图路径: 引用关系

多路融合: 加权打分
```

#### Stage 3: Context Ranking & Injection

```
LLM 重排:
- 理解连贯性
- 选择最优上下文组合

注入 LLM Context Window
```

### 推荐系统经验迁移

| 推荐系统 | 记忆召回系统 |
|---------|-------------|
| U2I/I2I/热门/规则 | Query-Memory / Memory-Memory / 高频 / 状态 |
| CTR×α + CVR×β + 时长×γ | 相关性×α + 时间×β + 重要性×γ + 连贯性×δ |
| 精准推荐 + 探索发现 | 精准召回核心记忆 + 关联记忆启发视角 |
| 用户行为序列预测 | 对话序列理解决策路径 |
| 实时/短期/长期/静态画像 | 当前对话/最近3天/长期记忆/静态画像 |

### 方法论收获

- ✅ 先抽象问题本质，再设计方案
- ✅ 充分利用 LLM 的理解能力，而非仅仅作为生成器
- ✅ 跨领域类比（推荐系统 → 记忆系统）可以带来架构层面的启发

---

## 阶段 3: 架构反思与调整

### 关键质疑

**问题**: 个人记忆系统是否真的需要双塔召回？

**核心洞察**:
- 推荐系统的双塔召回需要**海量数据**进行监督学习
- 个人记忆系统只有**千级数据**，没有足够的监督信号
- 盲目套用双塔架构 = **过度设计**

### 新架构思路：两层检索模型

**核心思想**: 将系统拆分为两层，每层针对不同的数据规模和约束。

#### 第一层：快速记忆检索
- **触发频率**: 每次对话（高频）
- **数据规模**: 个人记忆（千级）
- **核心约束**: Token 效率 + 速度
- **技术方案**: 规则召回 + 轻量排序（**不需要双塔**）

#### 第二层：海量知识检索
- **触发频率**: 按需触发（低频）
- **数据规模**: 外部知识库（亿级）
- **核心约束**: 深度 + 全面性
- **技术方案**: 双塔召回 + LLM 精排（**这里才需要推荐系统**）

### 对比分析

| 维度 | 初版方案（双塔召回） | 调整后方案（两层检索） |
|------|---------------------|-------------------|
| **第一层** | 双塔向量召回 | 规则召回 |
| **适用场景** | 海量数据 | 千级记忆 |
| **训练依赖** | 需要监督数据 | 不需要训练 |
| **Token 成本** | 较高 | 严格控制 |
| **速度** | 毫秒级（离线编码） | 秒级（在线匹配） |
| **第二层** | LLM 重排 | 双塔召回 + LLM 精排 |
| **数据源** | 只有记忆 | 记忆 + 外部知识库 |

### 设计反思

**核心认知转变**:
1. 初版方案**过度设计**了第一层
2. 第一层应该是**轻量、快速**的记忆检索，不需要复杂的双塔
3. 第二层才需要**推荐系统的能力**，处理海量外部数据
4. 两层的设计逻辑和约束完全不同，不能混为一谈

---

## 方法论总结

### 先抽象问题本质，再设计方案

- ✅ 跨会话记忆召回 = 双塔召回问题（阶段 2）
- ✅ 但个人记忆 ≠ 海量推荐数据（阶段 3）
- ✅ 需要分层设计：轻量规则（千级）+ 双塔召回（亿级）

### 机制要匹配任务特征

- 被动触发 vs 主动监控
- 工具类任务 vs 流程类任务
- 选对机制比修补更重要

### Token 效率优先

- 规则召回 < 1000 tokens
- 深度检索可以接受较高 token 成本（低频触发）
- 500 字节 Heartbeat > 4KB Skill

### 规模决定技术选型

- **千级数据** → 规则召回 + 轻量排序
- **亿级数据** → 双塔召回 + LLM 精排
- 不要盲目套用成熟方案，要根据实际规模选择

---

_下一步: [下一步计划](04-next-steps.md) - 如何推进项目？_
