# 关键讨论记录

本文档记录分身推荐系统演进过程中的重要讨论。

---

## 2026-02-19 | 分身项目的两个核心方向

### 用户提出的核心洞察

**方向 1: 记忆的自动化规划与处理**
- **当前**: 手动分类、定期整理
- **未来**: 自动识别重要性、自动归档、智能提取待办
- **关键**: 从「人驱动」转向「Agent 主动管理」

**方向 2: 主动发起对话，深化理解**
- **当前**: 被动响应，等待用户提问
- **未来**: 基于记忆推断用户可能关心的议题，主动抛出讨论
- **关键**: 从「问答工具」转向「主动参与的思考伙伴」

### 延伸思考

> "这两个方向其实是同一回事——记忆的价值在于被使用。不是为了存而存，是为了在合适的时机被唤醒、被关联、被讨论。分身不是「更好的搜索引擎」，而是「一直在场、主动思考的另一个你」。"

### 待探索问题

- 什么时机主动发起对话？（不打扰 vs 有价值）
- 如何量化「更理解用户」？（对齐度？预测准确度？）
- 记忆自动化的边界在哪里？（哪些必须人工确认？）

### 四检验框架（判断是否记录）

> 用户偏好：在某些关键讨论后，Agent 可以主动询问「要不要记下来」

**检验规则**：
1. **增量检验** - 相对于已有内容，是否带来新信息？
2. **回忆检验** - 一周后会记得吗？
3. **行为改变检验** - 会改变决策或行为吗？
4. **用户信号检验** - 有语气加强/结构化总结/情绪投入/反复强调吗？

**决策规则**: ≥2 个检验通过 → 主动建议记录

### 飞轮循环

> "两个重点：1) 记忆被很好的整理利用；2) 获取更多数据，主动询问用户或获取行为轨迹" - plancklin

```
更多数据输入（主动对话）
    ↓
更精准的用户画像
    ↓
更好的记忆整理（自动化）
    ↓
在正确时机调用正确信息
    ↓
主动对话质量提升
    ↓
用户更愿意分享
    ↓
回到起点
```

---

## 2026-02-20 | 双塔召回架构设计

### 触发背景

用户提问："之前我聊到过那个东西"时，如何更智能地召回相关记忆？

### 用户核心洞察 ⭐

> "无论是关键词、实体，还是向量匹配，都不够智能。比如'之前我聊到过xxx'，这个匹配不一定是硬匹配，甚至可能是隐含的意图。这三种方案都没有用到 LLM 的现有能力。"

> **"结合推荐系统，这个过程非常像双塔召回系统，但是 user 端的向量，需要更好的理解，用来检索记忆这个塔，来提供给 LLM 一个更好的上下文。"**

### 架构设计（三阶段）

#### Stage 1: Query Understanding (User Tower)

```
LLM Query Rewrite:
- 指代消解: "那个东西" → "大疆相机"
- 意图推断: "决定了" → 需要调用对比记录
- 实体提取: ["大疆相机", "Action 5 Pro", "Nano"]
```

#### Stage 2: Memory Retrieval (Dual Tower Recall)

```
多路召回:
├─ 实体路径: 根据实体查找
├─ 标签路径: 根据主题标签
├─ 向量路径: 语义相似度
├─ 时间路径: 最近讨论
└─ 图路径: 引用关系

多路融合: 加权打分
```

#### Stage 3: Context Ranking & Injection

```
LLM 重排:
- 理解连贯性
- 选择最优上下文组合

注入 LLM Context Window
```

### 推荐系统经验迁移

| 推荐系统 | 记忆召回系统 |
|---------|-------------|
| U2I/I2I/热门/规则 | Query-Memory / Memory-Memory / 高频 / 状态 |
| CTR×α + CVR×β + 时长×γ | 相关性×α + 时间×β + 重要性×γ + 连贯性×δ |
| 精准推荐 + 探索发现 | 精准召回核心记忆 + 关联记忆启发视角 |
| 用户行为序列预测 | 对话序列理解决策路径 |
| 实时/短期/长期/静态画像 | 当前对话/最近3天/MEMORY.md/USER.md |

### 方法论收获

- ✅ 先抽象问题本质，再设计方案
- ✅ 充分利用 LLM 的理解能力，而非仅仅作为生成器
- ✅ 跨领域类比（推荐系统 → 记忆系统）可以带来架构层面的启发

### 用户工作习惯（新识别）⭐

> **"记住一个我们讨论的习惯，在确认方案之前，不要做代码实现。"** - plancklin, 2026-02-20

含义: 先把问题和方案想透，达成共识，再动手。讨论和设计优先于编码。

---

## 2026-02-20 | Skill 机制的局限性反思

### 问题发现

**触发**: 用户发现 `memory-manager.skill` 从未被触发

**追问**: "为什么未被触发，是 skill 这个机制不适合做这种事情吗？"

### 核心矛盾（3 个）

1. **写入结构化 vs 读取机械化**
   - 写入时精心分类（insights/decisions/conversations）
   - 读取时却是简单的关键词匹配
   - 矛盾：组织方式和检索方式不匹配

2. **标签分类 vs 动态查询**
   - 预定义标签无法应对动态的提问方式
   - "之前那个关于xx的讨论" - 不一定带标签

3. **主动记录强调多 vs 主动调用强调少**
   - Memory-Manager 侧重"记得好"
   - 双塔召回侧重"用得好"

### Skill 机制局限性分析

**核心问题**: OpenClaw 的 Skill 机制是**被动触发**的（在"回复前"扫描当前消息），不适合需要**持续监控对话流程**、**等待时机主动介入**的任务。

**触发时机错位**:
- Skill 触发: 在"回复前"，基于当前消息
- Memory-Manager 需求: 在"回复后"，基于对话结束/话题切换
- **矛盾**: 只有回复完才知道"这段对话值得记录"，但那时已过触发时机

**无法主动轮询**:
- Skill 没有后台任务能力
- 只能在用户消息到来时被动检查
- 无法在"对话停顿 5 分钟"时主动介入

**触发条件模糊**:
- 描述依赖"思考结果"（如"判断是否有 insight"）而非"输入信号"
- 形成循环依赖: 要先判断有 insight 才会读 Skill，但不读 Skill 就不知道该判断什么

### Skill 适用性总结

| 任务类型 | Skill 是否适合 | 示例 |
|---------|---------------|------|
| **工具类** | ✅ 适合 | 天气查询、网页搜索、代码执行 |
| **参考文档** | ✅ 适合 | API 文档、操作指南 |
| **流程监控** | ❌ 不适合 | 对话记录建议、对话总结、主题追踪 |
| **状态管理** | ❌ 不适合 | 跨多轮对话的状态追踪 |

### 用户决策 ⭐

> "既然 skill 不适合做这种事情，我觉得应该删除 skill，把相关整理记忆的能力放到 HeartBeat.md 试试。内化规则也不宜过多，这样会增加 token 的负担。" - plancklin, 2026-02-20

**执行动作**:
- ✅ 删除 `skills/memory-manager/` 
- ✅ 创建轻量级 `HEARTBEAT.md`（约 500 字节）
- ✅ 配置 4 个检验规则

**Token 效率对比**:
- Memory-Manager Skill: ~4KB
- HEARTBEAT.md: ~500 字节
- **节省 87.5% Token**

### 方法论收获

- ✅ 机制设计要匹配任务特征（被动触发 vs 主动监控）
- ✅ 不要强行让工具做不适合的事，换个机制比修补更清晰
- ✅ Token 效率很重要：500 字节的 Heartbeat > 4KB 的 Skill

---

## 2026-02-21 | 架构调整 - 两层检索模型

### 触发背景

用户提出双塔结构在个人记忆系统中的适用性问题。

### 核心质疑

> "记忆召回的双塔结构存在一些问题，对于个人的记忆系统，其实没有必要用大量的数据去监督学习" - plancklin, 2026-02-21

**关键洞察**:
- 推荐系统的双塔召回需要**海量数据**进行监督学习
- 个人记忆系统只有**千级数据**，没有足够的监督信号
- 盲目套用双塔架构 = **过度设计**

### 用户提出的新架构思路

> "分身推荐系统为什么是个推荐系统？我觉得他分为两部分：
> 1. 对每个对话在记忆中的**快速检索** - 既要节省 token，也需要加快速度
> 2. 对问题进一步的**海量检索** - 比如推荐系统中的海量发表数据，进一步给出更好的回答" - plancklin, 2026-02-21

### 架构拆分

#### 第一层：快速记忆检索
- **触发频率**: 每次对话（高频）
- **数据规模**: 个人记忆（千级）
- **核心约束**: Token 效率 + 速度
- **技术方向**: 规则召回 + 轻量排序（**不需要双塔**）

#### 第二层：海量知识检索
- **触发频率**: 按需触发（低频）
- **数据规模**: 外部知识库（亿级）
- **核心约束**: 深度 + 全面性
- **技术方向**: 双塔召回 + LLM 精排（**这里才需要推荐系统**）

### 对比分析

| 维度 | 昨晚方案（双塔召回） | 新方案（两层检索） |
|------|---------------------|-------------------|
| **第一层** | 双塔向量召回 | 规则召回 |
| **适用场景** | 海量数据 | 千级记忆 |
| **训练依赖** | 需要监督数据 | 不需要训练 |
| **Token 成本** | 较高 | 严格控制 |
| **速度** | 毫秒级（离线编码） | 秒级（在线匹配） |
| **第二层** | LLM 重排 | 双塔召回 + LLM 精排 |
| **数据源** | 只有记忆 | 记忆 + 外部知识库 |

### Agent 的过度实现反思

**用户提醒**:
> "你这个回答好像违反了先讨论清楚再给实现" - plancklin, 2026-02-21

**问题**: Agent 在理解不充分时直接给出伪代码实现，跳过了架构讨论阶段

**正确流程**:
1. ✅ 先澄清概念和约束
2. ✅ 讨论架构分层的合理性
3. ✅ 明确每一层的输入输出和触发条件
4. ❌ 然后才是实现细节（而非立即给代码）

**更新到** `AGENTS.md` 的 "🎯 Working Together: Discussion First, Implementation Later" 章节。

### 当前理解（待验证）

**核心观点**:
1. 昨晚讨论的双塔召回**过度设计**了第一层
2. 第一层应该是**轻量、快速**的记忆检索，不需要复杂的双塔
3. 第二层才需要**推荐系统的能力**，处理海量外部数据
4. 两层的设计逻辑和约束完全不同，不能混为一谈

### 待澄清的关键问题

#### 关于第一层（快速检索）
- **Q1**: 触发时机？每次对话开始 or 用户问到时？
- **Q2**: Token 预算和速度要求的具体数值？
- **Q3**: 输出形式？直接注入 Context or 先展示给用户？

#### 关于第二层（海量检索）
- **Q4**: "海量发表数据"指什么？外部知识 or 更大范围的记忆？
- **Q5**: 触发条件？第一层不满足 or 用户明确要求 or 总是执行？
- **Q6**: "更好的回答"的评价标准？全面性？深刻性？可信度？

#### 关于整体定位
- **Q7**: 为什么最初叫"分身推荐系统"？
- **Q8**: 如果重新命名，应该叫什么？

---

## 方法论总结

### 讨论优先于实现

> "在确认方案之前，不要做代码实现。" - plancklin

**正确流程**:
1. 澄清问题和约束
2. 讨论架构分层的合理性
3. 明确输入输出和触发条件
4. 最后才是实现细节

### 先抽象问题本质，再设计方案

- ✅ 跨会话记忆召回 = 双塔召回问题（2026-02-20）
- ✅ 但个人记忆 ≠ 海量推荐数据（2026-02-21）
- ✅ 需要分层设计：轻量规则（千级）+ 双塔召回（亿级）

### 机制要匹配任务特征

- ✅ Skill 适合被动触发的工具类任务
- ❌ Skill 不适合需要主动监控的流程类任务
- ✅ Heartbeat 适合定期检查和状态监控

### Token 效率优先

- 500 字节 Heartbeat > 4KB Skill
- 规则召回 < 1000 tokens
- 深度检索可以接受较高 token 成本（低频触发）

---

_下一步: [下一步计划](04-next-steps.md) - 如何推进项目？_
